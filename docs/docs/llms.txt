# FastStream
> Open-source framework for building asynchronous web services that interact with event streams.Supports Kafka, RabbitMQ, NATS, Redis, and integrates seamlessly with FastAPI.

FastStream simplifies the process of writing producers and consumers for message queues, handling all the parsing, networking and documentation generation automatically.
Making streaming microservices has never been easier. Designed with junior developers in mind, FastStream simplifies your work while keeping the door open for more advanced use cases.


## Feature
- [Feature](https://faststream.ag2.ai/latest/faststream/): Effortless event stream integration for your services

## Tutorial
- [Getting Started](https://faststream.ag2.ai/latest/getting-started/): Quick start to use FastStream
- [Subscription and Serialization](https://faststream.ag2.ai/latest/getting-started/subscription/): FastStream provides a Message Broker agnostic way to subscribe to event streams.
- [Annotation Serialization](https://faststream.ag2.ai/latest/getting-started/subscription/annotation/): As you already know, FastStream serializes your incoming message body according to the function type annotations using Pydantic
- [Pydantic Serialization](https://faststream.ag2.ai/latest/getting-started/subscription/pydantic/): Besides, FastStream uses your handlers' annotations to collect information about the application schema and generate AsyncAPI schema.
- [Msgspec Serialization](https://faststream.ag2.ai/latest/getting-started/subscription/msgspec/): FastStream supports msgspec as an alternative backend for serialization, which can be used instead of Pydantic.
- [Filtering](https://faststream.ag2.ai/latest/getting-started/subscription/filtering/): FastStream also allows you to specify the message processing way using message headers, body type or something else. The filter feature enables you to consume various messages with different schemas within a single event stream.
- [Testing](https://faststream.ag2.ai/latest/getting-started/subscription/test/): Testability is a crucial part of any application, and FastStream provides you with the tools to test your code easily.
- [Dynamic Subscribers](https://faststream.ag2.ai/latest/getting-started/subscription/dynamic/): Sometimes, you need to process messages as they arrive without knowing their source at startup. Messages could be sent later via incoming messages, requests, or generated randomly for temporary queue processing. In such cases, you cannot use the regular FastStream @broker.subscriber() decorators.

## Publishing
- [Publishing](https://faststream.ag2.ai/latest/getting-started/publishing/): FastStream is broker-agnostic and easy to use, even as a client in non-FastStream applications.
- [Broker Publish](https://faststream.ag2.ai/latest/getting-started/publishing/broker/): The easiest way to publish a message is to use a Broker, which allows you to use it as a publisher client in any applications.
- [Decorator](https://faststream.ag2.ai/latest/getting-started/publishing/decorator/): The second-easiest way to publish messages is through the Publisher Decorator, which supports AsyncAPI and is ideal for quickly building applications, though it lacks full testing features. It creates a structured DataPipeline unit with input and output. The order of Subscriber and Publisher decorators is irrelevant, but @broker.publisher(...) can only be applied to functions already decorated by @broker.subscriber(...).
- [Object Decorator](https://faststream.ag2.ai/latest/getting-started/publishing/object/): The Publisher Object offers a comprehensive way to publish messages with AsyncAPI support and testability features. It creates a reusable Publisher object and can also function as a decorator. The order of Subscriber and Publisher decorators is irrelevant, but @publisher can only be used with functions already decorated by @broker.subscriber(...).
- [Direct Publishing](https://faststream.ag2.ai/latest/getting-started/publishing/direct/): The Publisher Object offers a comprehensive way to publish messages, featuring AsyncAPI support and testability. It creates a reusable Publisher object that can be used directly for message publishing.
- [Testing](https://faststream.ag2.ai/latest/getting-started/publishing/test/): Working with a Publisher object provides testing features such as an in-memory TestClient, local publishing with error propagation, and verification of the incoming message body.

## Routers
- [Routers](https://faststream.ag2.ai/latest/getting-started/routers/): FastStream's Broker Router allows you to split applications into modules, separate business logic from handler registration, and apply decoders, middleware, or dependencies to subscriber groups.

## Dependencies
- [Dependencies](https://faststream.ag2.ai/latest/getting-started/dependencies/): FastStream uses the secondary library FastDepends for dependency management. This dependency system is literally borrowed from FastAPI, so if you know how to work with that framework, you'll be comfortable with dependencies in FastStream.

## Context
- [Context](https://faststream.ag2.ai/latest/getting-started/context/): FastStreams has its own Dependency Injection container - Context, used to store application runtime objects and variables.
- [Existing Fields](https://faststream.ag2.ai/latest/getting-started/context/existed/): Context includes global objects such as the current broker, the context itself for custom fields, a logger that tags messages with message_id, and the raw message, while ensuring that the message is local to your current consumer scope through contextlib.ContextVar.
- [Custom Context](https://faststream.ag2.ai/latest/getting-started/context/custom/): You can also store your own objects in the Global and Local Context.
- [Fields Access](https://faststream.ag2.ai/latest/getting-started/context/fields/): Sometimes, you may need to use a different name for the argument (not the one under which it is stored in the context) or get access to specific parts of the object. To do this, simply specify the name of what you want to access, and the context will provide you with the object.
- [Extra Options](https://faststream.ag2.ai/latest/getting-started/context/extra/): Additionally, Context provides you with some extra capabilities for working with containing objects.

## Custom Serialization
- [Custom Serialization](https://faststream.ag2.ai/latest/getting-started/serialization/): By default, FastStream uses the JSON format to send and receive messages. However, if you need to handle messages in other formats or with additional serialization steps, such as gzip, lz4, Avro, Protobuf or Msgpack, you can easily modify the serialization logic.
- [Parser](https://faststream.ag2.ai/latest/getting-started/serialization/parser/): At this stage, FastStream serializes an incoming message from the broker's framework into a general format called StreamMessage. During this stage, the message body remains in the form of raw bytes. StreamMessage is a general representation of a message within FastStream. It contains all the information required for message processing within FastStreams.
- [Decoder](https://faststream.ag2.ai/latest/getting-started/serialization/decoder/): At this stage, the body of a StreamMessage is transformed into the format that it will take when it enters your handler function. This stage is the one you will need to redefine more often.
- [Examples](https://faststream.ag2.ai/latest/getting-started/serialization/examples/): Serialization examples with Protobuf, Msgpack and Avro. For data compression you can use  lz4 or zstd for compression algorithms. Also, you can still set a custom decoder at the Broker or Router level.

## Lifespan
- [Lifespan](https://faststream.ag2.ai/latest/getting-started/lifespan/): You can define logic to execute before launching the application, which runs once before it starts receiving messages, and also code to terminate processes after the application stops, executing once more after the main application completes. This lifecycle coverage is useful for initializing application settings, establishing database connection pools, or running machine learning models.
- [Hooks](https://faststream.ag2.ai/latest/getting-started/lifespan/hooks/): If your application uses Pydantic as a settings manager and has multiple .env files (like .env, .env.development, .env.test, .env.production) for different settings, FastStream enables you to switch between them at startup effortlessly by passing optional command-line arguments.
- [Context](https://faststream.ag2.ai/latest/getting-started/lifespan/context/): You can define startup and shutdown logic using the lifespan parameter of the FastStream app along with a context manager. To illustrate this, you can create an async function lifespan() that utilizes yield.
- [Testing](https://faststream.ag2.ai/latest/getting-started/lifespan/test/): In most cases, you test your subscriber and publisher functions, but occasionally you may need to trigger lifespan hooks in your tests as well. For this purpose, FastStream provides a special TestApp patcher that functions as a regular async context manager.

## Middlewares
- [Middlewares](https://faststream.ag2.ai/latest/getting-started/middlewares/): Middlewares in FastStream are a powerful mechanism for adding logic to any stage of the message processing pipeline, enabling features like integration with logging/metrics systems, application-level message serialization, rich message publishing, and more, with several methods to override for flexibility at the broker, router, or subscriber level.
- [Exception Middleware](https://faststream.ag2.ai/latest/getting-started/middlewares/exception/): FastStream offers a special ExceptionMiddleware for registering exception processors at the top level of your application, allowing you to create it, register handlers, and add it to the broker, router, or subscribers like regular middleware.

## AsyncAPI
- [Schema Export](https://faststream.ag2.ai/latest/getting-started/asyncapi/export/): This guide explains how to generate and serve AsyncAPI documentation for a FastStream application. Below is an example Python application that consumes data from a topic, increments the value, and outputs it to another topic. You can export AsyncAPI schema as JSON/YAML.
- [Schema Hosting](https://faststream.ag2.ai/latest/getting-started/asyncapi/hosting/): FastStream offers a command to serve AsyncAPI documentation via CLI, requiring an Internet connection to fetch the HTML through CDN.
- [Customize Information](https://faststream.ag2.ai/latest/getting-started/asyncapi/custom/): This guide explores how to customize AsyncAPI documentation for your FastStream application, including adding custom app info, broker details, handlers, and fine-tuning payload specifics.

## Integrations
- [HTTP Async Frameworks](https://faststream.ag2.ai/latest/getting-started/integrations/frameworks/): FastStream brokers are very easy to integrate with any of your applications: it is enough to initialize the broker at startup and close it correctly at the end of your application.
- [FastAPI Plugin](https://faststream.ag2.ai/latest/getting-started/integrations/fastapi/): FastStream can be used as a part of FastAPI. Just import a StreamRouter you need and declare the message handler in the same way as with a regular FastStream application.
- [Django](https://faststream.ag2.ai/latest/getting-started/integrations/django/): Using FastStream with Django. Django is a high-level Python web framework that promotes rapid development and clean design, allowing developers to focus on building applications without the hassle of web development. In this tutorial, we'll explore how to integrate the FastStream app with a Django application.

## CLI
- [CLI](https://faststream.ag2.ai/latest/getting-started/cli/): FastStream has its own built-in CLI tool for your maximum comfort as a developer.

## Acknowledgement
- [Acknowledgement](https://faststream.ag2.ai/latest/getting-started/acknowledgement/): Due to the possibility of unexpected errors during message processing, FastStream provides an ack_policy parameter that allows users to control how messages are handled. This parameter determines when and how messages should be acknowledged or rejected based on the result of the message processing.

## ASGI
- [ASGI](https://faststream.ag2.ai/latest/getting-started/asgi/): You often need to integrate your application with Prometheus metrics, K8S probes, and other observability features, which requires providing several HTTP endpoints; FastStream offers built-in ASGI support for basic functionality, allowing you to add custom ASGI routes and host AsyncAPI documentation in the same process, while also enabling reuse of the FastStream application object and compatibility with other ASGI frameworks.

## Observability
- [Healthchecks](https://faststream.ag2.ai/latest/getting-started/observability/healthcheks/): FastStream implements healthchecks through low-cost HTTP endpoints, allowing you to create liveness probes to detect when to restart a container and readiness probes to determine when a container is ready to accept traffic after completing initial tasks.
- [Prometheus](https://faststream.ag2.ai/latest/getting-started/observability/prometheus/): Prometheus is an open-source monitoring and alerting toolkit designed for reliability and scalability, enabling users to collect metrics, scrape data from various sources, store it efficiently, and query it in real-time, with a flexible data model and powerful query language that integrates seamlessly with Grafana for monitoring system and application health and performance.
- [OpenTelemetry](https://faststream.ag2.ai/latest/getting-started/observability/opentelemetry/): OpenTelemetry is an open-source observability framework that standardizes the collection and export of telemetry data, including traces, metrics, and logs, aiming to simplify integration and standardization across services and make observability a built-in feature of software development.
- [Tracing](https://faststream.ag2.ai/latest/getting-started/observability/opentelemetry/tracing/): Tracing is an observability method that tracks request flows through various services in a distributed system, providing insights into service interactions, performance bottlenecks, and errors, resulting in a detailed map of service interactions often visualized as a trace diagram, which helps developers understand application behavior and performance.
- [Baggage](https://faststream.ag2.ai/latest/getting-started/observability/opentelemetry/baggage/): OpenTelemetry Baggage is a context propagation mechanism for passing custom metadata across service boundaries, and FastStream offers an abstraction to initialize, propagate, modify, and stop propagating baggage through headers.
- [Sentry support](https://faststream.ag2.ai/latest/getting-started/observability/opentelemetry/sentry/): Sentry does not fully support OpenTelemetry due to its own context format, which is incompatible with Python implementations; however, you can export spans to Sentry by launching the OpenTelemetry Collector container, which converts traces to the Sentry format for export based on the specified DSN.
- [Logging](https://faststream.ag2.ai/latest/getting-started/observability/logging/): For application and access logging, use the broker's access_logger from the application context to log requests, change logging levels via the FastStream CLI, configure logging from a file, and utilize your own loggers since FastStream works with the standard logging.Logger; Structlog can also be integrated as a production-ready logging solution.

## Config Management
- [Config Management](https://faststream.ag2.ai/latest/getting-started/config/): To manage external settings like broker connections or database credentials, it's common to use environment variables, and Pydantic offers a utility for effectively handling these settings through its settings management feature.

## Task Scheduling
- [Task Scheduling](https://faststream.ag2.ai/latest/scheduling/): FastStream is designed for asynchronous service development and supports building distributed event-based systems, but task scheduling conflicts with its core ideology; however, you can integrate scheduling into your FastStream application using additional dependencies like Taskiq, an asynchronous distributed task queue, or other libraries that offer scheduling functionality.

## FastStream Project Template
- [FastStream Project Template](https://faststream.ag2.ai/latest/getting-started/template/): The Cookiecutter FastStream template is a versatile repository that offers a solid foundation for Python projects, including a basic application, testing infrastructure, linting scripts, and development tools to streamline your development process and maintain high code quality, whether starting a new application or enhancing an existing one.

## Kafka
- [Kafka Routing](https://faststream.ag2.ai/latest/kafka/kafka/): Kafka is an open-source distributed streaming platform developed by the Apache Software Foundation. It is designed to handle high-throughput, fault-tolerant, real-time data streaming.
- [AIOKafka](https://faststream.ag2.ai/latest/kafka/): The aiokafka library, is an asynchronous Kafka client for Python, built on top of the asyncio framework. It is designed to work seamlessly with asynchronous code, making it suitable for applications with high concurrency requirements.
- [Subscription](https://faststream.ag2.ai/latest/kafka/Subscriber/): To start consuming from a Kafka topic, simply decorate your consuming function with a @broker.subscriber(...) decorator, passing a string as a topic key.
- [Batch Subscriber](https://faststream.ag2.ai/latest/kafka/Subscriber/batch_subscriber/): If you want to consume data in batches, the @broker.subscriber(...) decorator makes it possible. By defining your consumed msg object as a list of messages and setting the batch parameter to True, the subscriber will call your consuming function with a batch of messages consumed from a single partition.
- [Publishing](https://faststream.ag2.ai/latest/kafka/Publisher/): The FastStream KafkaBroker supports all regular publishing use cases, and you can use them without any changes. However, if you wish to further customize the publishing logic, you should take a closer look at specific KafkaBroker parameters.
- [Batch Publishing](https://faststream.ag2.ai/latest/kafka/Publisher/batch_publisher/): If you need to send your data in batches, the @broker.publisher(...) decorator offers a convenient way to achieve this. To send data in batches using the @broker.publisher(...) decorator, set the batch argument to True when creating your publisher and return a tuple of messages in your producer function.
- [Publish With Key](https://faststream.ag2.ai/latest/kafka/Publisher/using_a_key/): Partition keys in Apache Kafka determine the appropriate partition for messages, keeping related messages together for order and efficient processing. They also help distribute load across brokers and ensure fault tolerance through data replication. You can specify partition keys using the @KafkaBroker.publisher(...) decorator in FastStream, and this guide will help you use them effectively.
- [Acknowledgement](https://faststream.ag2.ai/latest/kafka/ack/): Kafka consumers must commit a topic offset when consuming messages. By default, FastStream automatically commits offsets on consumption, following the "at most once" strategy. To use the "at least once" strategy, commit the offset after processing the message by setting a consumer group and disabling the auto_commit option.
- [Message Information](https://faststream.ag2.ai/latest/kafka/message/): FastStream serializes message bodies for access through function arguments, but you can also access additional attributes like offsets, headers, and metadata via the message object in the Context. This object wraps the native broker library message (e.g., aiokafka.ConsumerRecord for Kafka) and contains essential information.
- [Security Configuration](https://faststream.ag2.ai/latest/kafka/security/): This chapter covers FastStream's security options, including security objects for brokers that encapsulate configurations and mechanisms, with more planned in the future, such as SASL OAuth.
- [Confluent](https://faststream.ag2.ai/latest/confluent/): The Confluent Kafka Python library, developed by Confluent (the creators of Apache Kafka), offers a high-level producer and consumer API that integrates seamlessly with the Kafka ecosystem. It includes features like Avro serialization, schema registry integration, and performance tuning options, benefiting from strong support from the Kafka core team for better compatibility and a robust feature set.
- [Subscription](https://faststream.ag2.ai/latest/confluent/Subscriber/): To start consuming from a Kafka topic, simply decorate your consuming function with a @broker.subscriber(...) decorator, passing a string as a topic key.
- [Batch Subscriber](https://faststream.ag2.ai/latest/confluent/Subscriber/batch_subscriber/): To consume data in batches, use the @broker.subscriber(...) decorator. Define your consumed message object as a list and set the batch parameter to True. This configuration allows the subscriber to call your consuming function with a batch of messages from a single partition.
- [Publishing](https://faststream.ag2.ai/latest/confluent/Publisher/): The FastStream KafkaBroker supports all standard publishing use cases without any changes. However, for further customization of the publishing logic, you should explore specific KafkaBroker parameters.
- [Batch Publishing](https://faststream.ag2.ai/latest/confluent/Publisher/batch_publisher/): To send data in batches using the @broker.publisher(...) decorator, set the batch argument to True when creating your publisher and return a tuple of messages in your producer function to trigger batch transmission to the Kafka broker.
- [Publish With Key](https://faststream.ag2.ai/latest/confluent/Publisher/using_a_key/): Partition keys are crucial in Apache Kafka for determining the correct message partition, ensuring related messages remain together for order and efficient processing. They also aid in load distribution across brokers, enhance scalability, and provide fault tolerance through data replication. You can specify partition keys with the @KafkaBroker.publisher(...) decorator in FastStream, and this guide will help you use them effectively.
- [Acknowledgement](https://faststream.ag2.ai/latest/confluent/ack/): Kafka consumers must commit a topic offset when consuming messages. By default, FastStream automatically commits offsets upon consumption, following the "at most once" strategy. To implement the "at least once" strategy, commit the offset after processing the message by setting a consumer group and disabling auto_commit.
- [Message Information](https://faststream.ag2.ai/latest/confluent/message/): FastStream serializes message bodies for access through function arguments, but you may need to access additional attributes like offsets, headers, or metadata. You can easily access this information through the message object in the Context, which serves as a unified FastStream wrapper around the native broker library message (e.g., confluent_kafka.Message when using the Confluent Python library).
- [Security Configuration](https://faststream.ag2.ai/latest/confluent/security/): This chapter covers the security options available in FastStream and their usage. FastStream enhances application security by using security objects when creating brokers, which encapsulate security-related configurations and mechanisms. Currently supported security objects include (with more planned in the future, such as SASL OAuth).
- [Additional Configuration](https://faststream.ag2.ai/latest/confluent/additional-configuration/): The confluent-kafka-python package is a Python wrapper around librdkafka, a C/C++ client library for Apache Kafka. It accepts a config dictionary that is passed to librdkafka, which offers numerous configuration properties for the Kafka client. FastStream also allows users to pass a config dictionary to librdkafka for greater customizability.
- [How-To](https://faststream.ag2.ai/latest/howto/kafka/): Kafka is a complex tool, and the FastStream KafkaBroker API can be challenging in certain cases. While our main documentation covers the primary FastStream and Kafka concepts, this section offers concrete FastStream-Kafka examples that you can use as copy-paste code in your services or as a reference.
- [Kafka RPC](https://faststream.ag2.ai/latest/howto/kafka/rpc/): Kafka lacks a built-in RPC mechanism or zero-cost topics, but you can emulate this behavior using a messaging pattern. To do this, create a persistent topic to consume the response stream and match responses with requests using a correlation ID. This can be easily implemented with FastStream.

## RabbitMQ
- [Rabbit Routing](https://faststream.ag2.ai/latest/rabbit/): The advantage of RabbitMQ lies in its ability to configure flexible and complex message routing scenarios. It supports a wide range of routing options, from one queue with one consumer to a queue sourced from multiple inputs, including message prioritization.
- [Subscription](https://faststream.ag2.ai/latest/rabbit/examples/): Even if you're unfamiliar with RabbitMQ, you can still use FastStream's RabbitBroker. Simply use the @broker.subscriber(...) method with a string as a routing key.
- [Direct](https://faststream.ag2.ai/latest/rabbit/examples/direct/): The Direct Exchange is the basic way to route messages in RabbitMQ. Its core is very simple: the exchange sends messages to those queues whose routing_key matches the routing_key of the message being sent.
- [Fanout](https://faststream.ag2.ai/latest/rabbit/examples/fanout/): The Fanout Exchange is a straightforward, though less popular, routing method in RabbitMQ. It sends messages to all queues subscribed to it, disregarding any message arguments. Additionally, if a queue has multiple consumers, messages will be distributed among them as part of the default scaling mechanism.
- [Topic](https://faststream.ag2.ai/latest/rabbit/examples/topic/): The Topic Exchange is a powerful routing tool in RabbitMQ. It sends messages to queues based on patterns specified during their connection to the exchange and the message's routing key. Additionally, if a queue has multiple consumers, messages will be distributed among them as part of the default scaling mechanism.
- [Headers](https://faststream.ag2.ai/latest/rabbit/examples/headers/): The Header Exchange is the most complex and flexible routing method in RabbitMQ. It sends messages to queues by matching the queue binding arguments with message headers. Additionally, if a queue has multiple consumers, messages will be distributed among them as part of the default scaling mechanism.
- [Stream](https://faststream.ag2.ai/latest/rabbit/examples/stream/): RabbitMQ has a Streams feature that is similar to Kafka topics. The main difference is that messages are not deleted after consumption, unlike regular RabbitMQ queues. FastStream also supports this feature!
- [Publishing](https://faststream.ag2.ai/latest/rabbit/publishing/): FastStream RabbitBroker supports all standard publishing use cases without any changes. However, for further customization of the publishing logic, you should explore specific RabbitBroker parameters in more detail.
- [RPC](https://faststream.ag2.ai/latest/rabbit/rpc/): FastStream allows you to send a blocking RPC request over RabbitMQ easily. It utilizes the Direct Reply-To feature, eliminating the need to create queues for consuming responses. Simply send a message like a regular one and receive a response synchronously, closely resembling common request syntax.
- [Acknowledgement](https://faststream.ag2.ai/latest/rabbit/ack/): RabbitMQ has a comprehensive Acknowledgement policy. FastStream typically acknowledges (acks) messages automatically on your behalf; when your function executes successfully, the message is acknowledged, and it is rejected in case of an exception. However, there may be situations where you want to implement a different acknowledgement logic.
- [Declare Queue/Exchange](https://faststream.ag2.ai/latest/rabbit/declare/): FastStream subscribers automatically declare and validate RabbitMQ exchanges and queues (publishers only declare exchanges), but there are times when you may need to declare them manually. RabbitBroker offers an easy way to accomplish this.
- [Message Information](https://faststream.ag2.ai/latest/rabbit/message/): FastStream serializes message bodies for access through function arguments, but you may sometimes need access to the message ID, headers, or other meta-information. You can easily obtain this by accessing the message object in the Context.
- [Security Configuration](https://faststream.ag2.ai/latest/rabbit/security/): This chapter covers the security options available in FastStream and their usage. FastStream enhances application security by utilizing security objects when creating brokers, which encapsulate security-related configurations and mechanisms.

## NATS
- [NATS](https://faststream.ag2.ai/latest/nats/): NATS is a high-performance, easy-to-use message broker written in Golang. It's an excellent choice for applications that don't require complex routing logic, can handle high loads, scale efficiently, and minimize hardware costs. Additionally, NATS allows for zero-cost creation of new entities (as all subjects are simply routing fields), making it suitable for RPC over MQ use cases.
- [Subscription](https://faststream.ag2.ai/latest/nats/examples/): NATS examples
- [Direct](https://faststream.ag2.ai/latest/nats/examples/direct/): The Direct Subject is the basic way to route messages in NATS. Its essence is very simple: a subject sends messages to all consumers subscribed to it.
- [Pattern](https://faststream.ag2.ai/latest/nats/examples/pattern/): Pattern Subject is a powerful NATS routing engine. This type of subject routes messages to consumers based on the pattern specified when they connect to the subject and a message key.
- [JetStream](https://faststream.ag2.ai/latest/nats/jetstream/): The default NATS usage is ideal for scenarios where the publisher and consumer are always online and the system can tolerate message loss. However, if you require stricter conditions, such as a message processing confirmation mechanism (ack/nack) and message persistence (accumulating messages in the queue when the consumer is offline), you should use the NATS JetStream extension.
- [Pull Subscriber](https://faststream.ag2.ai/latest/nats/jetstream/pull/): NATS JetStream offers two ways to consume messages: Push and Pull consumers. The default Push consumer automatically delivers messages, but it increases server load as NATS manages all consumer connections. The NATS team recommends the Pull consumer, where you request messages at intervals.
- [Key-Value Storage](https://faststream.ag2.ai/latest/nats/jetstream/key-value/): Key-Value storage in NATS JetStream is a high-level interface where each KV key corresponds to a subject, allowing you to put/update objects like publishing messages, retrieve current and historical values, and subscribe to key changes.
- [Object Storage](https://faststream.ag2.ai/latest/nats/jetstream/object/): Object Storage is similar to Key-Value storage in NATS JetStream, functioning as a high-level interface where each object key corresponds to a subject. The key difference is that Object Storage allows you to store files larger than 1MB (unlike KV), with no maximum size limit, as it stores objects in chunks (each message is an object chunk), enabling the streaming of large objects through NATS.
- [Acknowledgement](https://faststream.ag2.ai/latest/nats/jetstream/ack/): NATS has a comprehensive Acknowledgement policy. FastStream typically acknowledges (acks) messages automatically; when your function executes successfully, the message is acknowledged, and it is rejected in case of an exception. However, there may be situations where you want to implement different acknowledgement logic.
- [Publishing](https://faststream.ag2.ai/latest/nats/publishing/): FastStream NatsBroker supports all standard publishing use cases without any changes. However, for further customization of the publishing logic, you should explore specific NatsBroker parameters in more detail.
- [RPC](https://faststream.ag2.ai/latest/nats/rpc/): NATS allows for zero-cost creation of new subjects, enabling you to set up a dedicated subject consumer for a single response message. This means your request message can be published to one topic while the response is consumed from a temporary subject, allowing you to use regular FastStream RPC syntax in the NATS context as well.
- [Message Information](https://faststream.ag2.ai/latest/nats/message/): FastStream serializes message bodies for access through function arguments, but you may need to access the message ID, headers, or other meta-information. You can easily obtain this by accessing the message object in the Context.
- [How-To](https://faststream.ag2.ai/latest/howto/nats/): NATS is a complex tool, and the FastStream NatsBroker API can be challenging in certain cases. While our main documentation covers the primary FastStream and NATS concepts, this section offers concrete FastStream-NATS examples that you can use as copy-paste code in your services or as a reference.
- [DynaConf](https://faststream.ag2.ai/latest/howto/nats/dynaconf/): As NATS has key-value storage, you can use it as a configuration storage solution. Here is an example of how to use it with FastStream.
- [In-Progress](https://faststream.ag2.ai/latest/howto/nats/in-progress/): NATS JetStream follows the "at least once" principle, meaning messages will be delivered until they receive an ACK status, even if your handler takes a long time to process the message. This allows you to extend the message processing status with a request.

## Redis
- [Redis](https://faststream.ag2.ai/latest/redis/): Redis is an open-source, in-memory data structure store used as a database, cache, and message broker. It supports various data structures like strings, hashes, lists, and geospatial indexes. Redis offers built-in replication, Lua scripting, LRU eviction, transactions, and high availability through Redis Sentinel and automatic partitioning with Redis Cluster.
- [Pub/Sub](https://faststream.ag2.ai/latest/redis/pubsub/): Redis Pub/Sub Channels enable messaging between clients using a publish/subscribe (pub/sub) pattern. A Redis channel serves as a medium for transmitting messages, allowing different clients to subscribe to listen for messages while others publish messages to these channels.
- [Subscription](https://faststream.ag2.ai/latest/redis/pubsub/subscription/): Redis Pub/Sub is the default subscriber type in FastStream, so you can simply create a regular @broker.subscriber("channel_name") with a channel name and it creates a subscriber using Redis Pub/Sub.
- [Publishing](https://faststream.ag2.ai/latest/redis/pubsub/publishing/): The FastStream RedisBroker supports all standard publishing use cases, similar to the KafkaBroker, enabling easy message publishing to Redis channels. Below, you'll find guidance on utilizing the RedisBroker for publishing messages, including creating publisher objects and using decorators for streamlined workflows.
- [List](https://faststream.ag2.ai/latest/redis/list/): Redis Lists are ordered collections of strings that function as a simple and flexible data structure. Similar to lists in programming languages, Redis provides commands for various operations, including adding, retrieving, and removing elements from either end. Redis Lists are especially useful for implementing queues, allowing the list to operate as a FIFO (First-In-First-Out) structure.
- [Subscription](https://faststream.ag2.ai/latest/redis/list/subscription/): To start consuming from a Redis list, simply decorate your consuming function with the @broker.subscriber(...) decorator, passing a string as the list key.
- [Publishing](https://faststream.ag2.ai/latest/redis/list/publishing/): Using the FastStream library, you can publish data to Redis lists, which function as queues in Redis-based messaging systems. Similar to Redis streams, messages can be published to Redis lists. FastStream employs the @broker.publisher(...) decorator, along with the list's name, to push messages onto the list.
- [Batching](https://faststream.ag2.ai/latest/redis/list/batch/): To consume data in batches from a Redis list, use the @broker.subscriber(...) decorator. By defining your consumed message object as a list of messages and setting the batch parameter to True within the ListSub object, the subscriber will call your consuming function with a batch of messages. Let's explore how to achieve this with the FastStream library.
- [Streams](https://faststream.ag2.ai/latest/redis/streams/): Redis Streams, introduced in Redis 5.0, offer a reliable and scalable way to handle data streams, similar to Apache Kafka. They store data in a log structure for multiple clients to consume, providing ordered messages designed for high volume through partitioning.
- [Subscription](https://faststream.ag2.ai/latest/redis/streams/subscription/): To start consuming from a Redis stream, simply decorate your consuming function with the @broker.subscriber(...) decorator, passing a string as the stream key.
- [Publishing](https://faststream.ag2.ai/latest/redis/streams/publishing/): To publish messages to a Redis Stream, implement a function that processes the incoming data and applies the @broker.publisher(...) decorator with the Redis stream name. The function will then publish its return value to the specified stream.
- [Groups](https://faststream.ag2.ai/latest/redis/streams/groups/): Consuming messages from a Redis stream can be done using a Consumer Group, which enables multiple consumers to share the workload of processing messages. This approach also provides message acknowledgment, ensuring that messages are not processed repeatedly.
- [Batching](https://faststream.ag2.ai/latest/redis/streams/batch/): To consume data in batches from a Redis stream, use the @broker.subscriber(...) decorator, define your consumed message object as a list, and set the batch parameter to True in the StreamSub object. This allows the subscriber to call your function with a batch of messages. Let's see how to do this with the FastStream library.
- [Acknowledgement](https://faststream.ag2.ai/latest/redis/streams/ack/): When using Redis streams in the FastStream library, it's crucial to manage message acknowledgments to prevent message loss and ensure proper processing. By default, FastStream automatically acknowledges (acks) messages as processed, adhering to the "at most once" processing guarantee.
- [RPC](https://faststream.ag2.ai/latest/redis/rpc/): FastStream RedisBroker enables powerful Remote Procedure Calls (RPC) using Redis, allowing you to send a message and await a response, effectively creating a synchronous request-response pattern over Redis's asynchronous messaging system. Below is a guide to set up and utilize the Redis RPC publishing feature with FastStream.
- [Pipeline](https://faststream.ag2.ai/latest/redis/pipeline/): FastStream supports Redis pipelining to optimize performance when publishing multiple messages in a batch. This allows you to queue several Redis operations and execute them in one network round-trip, reducing latency significantly.
- [Message Information](https://faststream.ag2.ai/latest/redis/message/): In FastStream, messages passed through a Redis broker are serialized and can be interacted with just like function parameters. However, you might occasionally need to access more than just the message content, such as metadata and other attributes.
- [Security Configuration](https://faststream.ag2.ai/latest/redis/security/): This chapter covers the security options available in FastStream and their usage. FastStream enhances application security by utilizing security objects when creating brokers, which encapsulate security-related configurations and mechanisms.
- [Message Format](https://faststream.ag2.ai/latest/redis/message_format/): To offer features like observability, FastStream includes extra data in your messages. Redis allows sending any type of data within a message, so FastStream uses its own binary format for messages, supporting any data type and additional information you wish to include.

## Reference - Code API
- [Reference - Code API](https://faststream.ag2.ai/latest/api/): Hereâ€™s the reference for the code API, including classes, functions, parameters, attributes, and all FastAPI components you can use in your applications. For a better understanding of FastStream, it's recommended to read the FastStream Tutorial.
- [Public API](https://faststream.ag2.ai/latest/public_api/faststream/BaseMiddleware/): This section contains information about Public FastStream API
- [All API](https://faststream.ag2.ai/latest/api/faststream/BaseMiddleware/): This section contains information about All FastStream API

## FastStream People
- [FastStream People](https://faststream.ag2.ai/latest/faststream-people/): FastStream has an amazing community that welcomes people from all backgrounds. The following are the top contributors to FastStream.

## Contributing
- [Contributing](https://faststream.ag2.ai/latest/getting-started/contributing/): How to contribute to the project
- [Development](https://faststream.ag2.ai/latest/getting-started/contributing/CONTRIBUTING/):  How to  set up dev environment and code contributions
- [Documentation](https://faststream.ag2.ai/latest/getting-started/contributing/docs/): How to write and improve documentation

## Release Notes
- [Release Notes](https://faststream.ag2.ai/latest/release/): FastStream Release Notes and changelog
